{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../flower_data/'\n",
    "TRAIN, VAL, TEST = 'train', 'valid', 'test'\n",
    "\n",
    "train_in_file = os.path.join(data_dir, TRAIN)\n",
    "valid_in_file = os.path.join(data_dir, VAL)\n",
    "\n",
    "input_size = (224, 224) # This size is dertermined by the size from VGG-19\n",
    "channels = 3 # RGB\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "num_train_samples = 4000\n",
    "num_valid_samples= 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6552 images belonging to 102 classes.\n",
      "Found 818 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    rescale=0.5,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.4,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    rescale=0.5,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.4,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_in_file, target_size=input_size)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_in_file, target_size=input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(input_size[0], input_size[1], channels)\n",
    ")\n",
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our data is similar to images in ImageNet database, and it\n",
    "# can be considered as small (only few thousands of images in total),\n",
    "# we can freeze the all the layers except the fully-connected (FC) layers\n",
    "# since we can expect the higher-level featuers in the pre-trained model\n",
    "# to be relevant to our data, so we only train them (the FC layers).\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Now add some custom layers into our model\n",
    "net = vgg19.output\n",
    "net = Flatten()(net)\n",
    "net = Dense(512, activation='relu')(net)\n",
    "net = Dropout(0.2)(net)\n",
    "net = Dense(256, activation='relu')(net)\n",
    "net = Dense(train_generator.num_classes, activation='softmax')(net)\n",
    "\n",
    "# Create our main model\n",
    "predicted_model = Model(inputs=vgg19.input, outputs=net)\n",
    "predicted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model\n",
    "predicted_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'vgg19.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=10,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='auto',\n",
    "    min_delta=0.5, # Tuning this parameter for smallest amount to be `improvement`\n",
    "    patience=1, # number of epochs with no improvement after which we stop\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    nb_val_samples=valid_samples,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
